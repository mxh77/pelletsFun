const fs = require('fs');
const path = require('path');
const mongoose = require('mongoose');
require('dotenv').config({ path: './backend/.env' });

const BoilerData = require('./backend/models/BoilerData');

async function checkImportService() {
  try {
    console.log('ğŸ” DIAGNOSTIC DU SERVICE D\'IMPORT');
    console.log('==================================\n');

    // 1. VÃ©rifier les fichiers CSV dans auto-downloads
    const autoDownloadsPath = path.join(__dirname, 'backend', 'auto-downloads');
    
    console.log('ğŸ“ ANALYSE DES FICHIERS CSV');
    console.log('----------------------------');
    
    if (fs.existsSync(autoDownloadsPath)) {
      const csvFiles = fs.readdirSync(autoDownloadsPath)
        .filter(file => file.endsWith('.csv'))
        .map(file => {
          const filePath = path.join(autoDownloadsPath, file);
          const stats = fs.statSync(filePath);
          return {
            name: file,
            size: stats.size,
            modified: stats.mtime,
            sizeKB: (stats.size / 1024).toFixed(2)
          };
        })
        .sort((a, b) => b.modified - a.modified);

      console.log(`ğŸ“Š ${csvFiles.length} fichiers CSV trouvÃ©s:`);
      csvFiles.forEach(file => {
        console.log(`   ${file.name} - ${file.sizeKB} KB - ${file.modified.toLocaleDateString()}`);
      });

      const totalSizeKB = csvFiles.reduce((sum, file) => sum + file.size, 0) / 1024;
      console.log(`   ğŸ“¦ Taille totale: ${totalSizeKB.toFixed(2)} KB\n`);
    } else {
      console.log('âŒ Dossier auto-downloads non trouvÃ©\n');
    }

    // 2. Analyser le service d'import
    const autoImportServicePath = path.join(__dirname, 'backend', 'services', 'autoImportService.js');
    
    console.log('âš™ï¸  ANALYSE DU SERVICE D\'IMPORT');
    console.log('-------------------------------');
    
    if (fs.existsSync(autoImportServicePath)) {
      const serviceContent = fs.readFileSync(autoImportServicePath, 'utf8');
      
      // Chercher des patterns problÃ©matiques
      const issues = [];
      
      if (!serviceContent.includes('findOne') && !serviceContent.includes('exists')) {
        issues.push('âš ï¸  Pas de vÃ©rification de doublons dÃ©tectÃ©e');
      }
      
      if (serviceContent.includes('insertMany') || serviceContent.includes('create')) {
        issues.push('â„¹ï¸  Utilise des insertions en lot (risque de doublons)');
      }
      
      if (!serviceContent.includes('filename')) {
        issues.push('âš ï¸  Pas de tracking des noms de fichiers dÃ©tectÃ©');
      }
      
      if (serviceContent.includes('setInterval') || serviceContent.includes('cron')) {
        issues.push('â„¹ï¸  Service automatique dÃ©tectÃ©');
      }

      if (issues.length > 0) {
        console.log('ğŸš¨ ProblÃ¨mes potentiels dÃ©tectÃ©s:');
        issues.forEach(issue => console.log(`   ${issue}`));
      } else {
        console.log('âœ… Service semble correct');
      }
    } else {
      console.log('âŒ Service autoImportService.js non trouvÃ©');
    }

    // 3. Analyser la base de donnÃ©es
    console.log('\nğŸ“Š ANALYSE DE LA BASE DE DONNÃ‰ES');
    console.log('---------------------------------');
    
    await mongoose.connect(process.env.MONGODB_URI);
    
    const totalEntries = await BoilerData.countDocuments();
    console.log(`Total d'entrÃ©es BoilerData: ${totalEntries.toLocaleString()}`);
    
    if (totalEntries > 0) {
      // Analyser les imports rÃ©cents
      const recentImports = await BoilerData.aggregate([
        {
          $group: {
            _id: {
              filename: '$filename',
              importDate: { $dateToString: { format: '%Y-%m-%d', date: '$importDate' } }
            },
            count: { $sum: 1 },
            firstEntry: { $min: '$importDate' },
            lastEntry: { $max: '$importDate' }
          }
        },
        { $sort: { firstEntry: -1 } },
        { $limit: 10 }
      ]);

      console.log('\nğŸ“… 10 derniers imports:');
      recentImports.forEach(imp => {
        console.log(`   ${imp._id.filename} (${imp._id.importDate}): ${imp.count} entrÃ©es`);
      });

      // DÃ©tection des doublons
      const duplicates = await BoilerData.aggregate([
        {
          $group: {
            _id: '$filename',
            count: { $sum: 1 },
            imports: { $addToSet: { $dateToString: { format: '%Y-%m-%d %H:%M', date: '$importDate' } } }
          }
        },
        {
          $match: { count: { $gt: 1 } }
        },
        { $sort: { count: -1 } },
        { $limit: 5 }
      ]);

      if (duplicates.length > 0) {
        console.log('\nğŸ”´ TOP 5 des fichiers avec doublons:');
        duplicates.forEach(dup => {
          console.log(`   ${dup._id}: ${dup.count} entrÃ©es (importÃ© ${dup.imports.length} fois)`);
          dup.imports.slice(0, 3).forEach(imp => console.log(`      - ${imp}`));
          if (dup.imports.length > 3) {
            console.log(`      ... et ${dup.imports.length - 3} autres imports`);
          }
        });
      }
    }

    // 4. Recommandations
    console.log('\nğŸ’¡ RECOMMANDATIONS');
    console.log('------------------');
    console.log('1. ğŸ” Lancez d\'abord: node analyze-mongodb-space.js');
    console.log('2. ğŸ§¹ Nettoyez les doublons: node cleanup-mongodb.js --duplicates-only');
    console.log('3. âš™ï¸  Modifiez autoImportService.js pour Ã©viter les doublons futurs');
    console.log('4. ğŸ“Š Surveillez rÃ©guliÃ¨rement avec ce script de diagnostic');

  } catch (error) {
    console.error('âŒ Erreur lors du diagnostic:', error);
  } finally {
    if (mongoose.connection.readyState === 1) {
      await mongoose.disconnect();
    }
    console.log('\nâœ… Diagnostic terminÃ©');
  }
}

checkImportService();