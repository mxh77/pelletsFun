const mongoose = require('mongoose');
require('dotenv').config({ path: './backend/.env' });

const BoilerData = require('./backend/models/BoilerData');

async function cleanupDatabase() {
  try {
    console.log('üîå Connexion √† MongoDB...');
    await mongoose.connect(process.env.MONGODB_URI);
    console.log('‚úÖ Connect√© avec succ√®s\n');

    console.log('üßπ NETTOYAGE DE LA BASE DE DONN√âES');
    console.log('===================================');

    // Statistiques initiales
    const initialCount = await BoilerData.countDocuments();
    const db = mongoose.connection.db;
    const initialStats = await db.collection('boilerdatas').stats();
    
    console.log(`üìä AVANT NETTOYAGE:`);
    console.log(`   Nombre d'entr√©es: ${initialCount.toLocaleString()}`);
    console.log(`   Taille des donn√©es: ${(initialStats.size / 1024 / 1024).toFixed(2)} MB\n`);

    // 1. Supprimer les doublons
    console.log('üîç Recherche des doublons...');
    
    const duplicateFiles = await BoilerData.aggregate([
      {
        $group: {
          _id: '$filename',
          docs: { $push: { id: '$_id', importDate: '$importDate' } },
          count: { $sum: 1 }
        }
      },
      {
        $match: {
          count: { $gt: 1 }
        }
      }
    ]);

    if (duplicateFiles.length > 0) {
      console.log(`‚ùå ${duplicateFiles.length} fichiers avec doublons trouv√©s`);
      
      let totalDeleted = 0;
      for (const file of duplicateFiles) {
        // Garder seulement l'import le plus r√©cent
        const sortedDocs = file.docs.sort((a, b) => new Date(b.importDate) - new Date(a.importDate));
        const toDelete = sortedDocs.slice(1).map(doc => doc.id);
        
        console.log(`   Suppression de ${toDelete.length} doublons pour ${file._id}`);
        await BoilerData.deleteMany({ _id: { $in: toDelete } });
        totalDeleted += toDelete.length;
      }
      
      console.log(`‚úÖ ${totalDeleted} doublons supprim√©s\n`);
    } else {
      console.log('‚úÖ Aucun doublon trouv√©\n');
    }

    // 2. Analyser les anciennes donn√©es
    console.log('üìÖ Analyse des anciennes donn√©es...');
    
    const oneYearAgo = new Date();
    oneYearAgo.setFullYear(oneYearAgo.getFullYear() - 1);
    
    const sixMonthsAgo = new Date();
    sixMonthsAgo.setMonth(sixMonthsAgo.getMonth() - 6);
    
    const oldDataCount = await BoilerData.countDocuments({
      date: { $lt: oneYearAgo }
    });

    const veryOldDataCount = await BoilerData.countDocuments({
      date: { $lt: sixMonthsAgo }
    });

    console.log(`üìä Donn√©es anciennes:`);
    console.log(`   Plus de 6 mois: ${veryOldDataCount.toLocaleString()} entr√©es`);
    console.log(`   Plus d'un an: ${oldDataCount.toLocaleString()} entr√©es`);

    if (oldDataCount > 0) {
      console.log(`\n‚ö†Ô∏è  ATTENTION: ${oldDataCount} entr√©es de plus d'un an trouv√©es`);
      console.log('üí° Pour les supprimer, d√©commentez les lignes dans le script et relancez:');
      console.log('   // await BoilerData.deleteMany({ date: { $lt: oneYearAgo } });');
      console.log('   // console.log(`‚úÖ ${oldDataCount} anciennes entr√©es supprim√©es`);');
    } else {
      console.log('‚úÖ Aucune donn√©e ancienne trouv√©e');
    }

    // 3. Option de suppression des tr√®s anciennes donn√©es (d√©commentez si n√©cessaire)
    /*
    if (oldDataCount > 0) {
      console.log(`üóëÔ∏è  Suppression des donn√©es de plus d'un an...`);
      const deleteResult = await BoilerData.deleteMany({ date: { $lt: oneYearAgo } });
      console.log(`‚úÖ ${deleteResult.deletedCount} anciennes entr√©es supprim√©es`);
    }
    */

    // 4. Statistiques apr√®s nettoyage
    console.log('\nüìä STATISTIQUES APR√àS NETTOYAGE');
    console.log('================================');
    
    const finalCount = await BoilerData.countDocuments();
    const finalStats = await db.collection('boilerdatas').stats();
    
    console.log(`Nombre total d'entr√©es: ${finalCount.toLocaleString()}`);
    console.log(`Taille des donn√©es: ${(finalStats.size / 1024 / 1024).toFixed(2)} MB`);
    console.log(`Taille moyenne par document: ${(finalStats.avgObjSize / 1024).toFixed(2)} KB`);
    
    const spaceSaved = initialStats.size - finalStats.size;
    if (spaceSaved > 0) {
      console.log(`üíæ Espace lib√©r√©: ${(spaceSaved / 1024 / 1024).toFixed(2)} MB`);
    }

    // 5. Compactage de la collection (optionnel)
    console.log('\nüóúÔ∏è  COMPACTAGE DE LA COLLECTION');
    console.log('===============================');
    console.log('‚ö†Ô∏è  Le compactage peut prendre du temps et verrouille la collection...');
    console.log('üí° Pour compacter, d√©commentez les lignes suivantes et relancez:');
    console.log('   // console.log("üîÑ Compactage en cours...");');
    console.log('   // await db.runCommand({ compact: "boilerdatas" });');
    console.log('   // console.log("‚úÖ Collection compact√©e");');

    /*
    // D√©commentez pour compacter
    console.log('üîÑ Compactage en cours...');
    await db.runCommand({ compact: 'boilerdatas' });
    console.log('‚úÖ Collection compact√©e');
    */

    // 6. Recommandations finales
    console.log('\nüí° RECOMMANDATIONS');
    console.log('==================');
    console.log('1. üîÑ Modifier autoImportService.js pour √©viter les doublons');
    console.log('2. ‚è∞ Impl√©menter une t√¢che cron pour nettoyer automatiquement');
    console.log('3. üìä Surveiller r√©guli√®rement la taille de la base');
    console.log('4. üóúÔ∏è  Compacter la collection apr√®s de gros nettoyages');

  } catch (error) {
    console.error('‚ùå Erreur lors du nettoyage:', error);
  } finally {
    await mongoose.disconnect();
    console.log('\nüîå Connexion ferm√©e');
  }
}

// Fonction pour nettoyer seulement les doublons (plus s√ªr)
async function cleanDuplicatesOnly() {
  try {
    console.log('üîå Connexion √† MongoDB...');
    await mongoose.connect(process.env.MONGODB_URI);
    console.log('‚úÖ Connect√© avec succ√®s\n');

    console.log('üßπ SUPPRESSION DES DOUBLONS UNIQUEMENT');
    console.log('======================================');

    const duplicateFiles = await BoilerData.aggregate([
      {
        $group: {
          _id: '$filename',
          docs: { $push: { id: '$_id', importDate: '$importDate' } },
          count: { $sum: 1 }
        }
      },
      {
        $match: {
          count: { $gt: 1 }
        }
      }
    ]);

    if (duplicateFiles.length > 0) {
      console.log(`‚ùå ${duplicateFiles.length} fichiers avec doublons trouv√©s`);
      
      let totalDeleted = 0;
      for (const file of duplicateFiles) {
        const sortedDocs = file.docs.sort((a, b) => new Date(b.importDate) - new Date(a.importDate));
        const toDelete = sortedDocs.slice(1).map(doc => doc.id);
        
        console.log(`   Suppression de ${toDelete.length} doublons pour ${file._id}`);
        await BoilerData.deleteMany({ _id: { $in: toDelete } });
        totalDeleted += toDelete.length;
      }
      
      console.log(`‚úÖ ${totalDeleted} doublons supprim√©s au total`);
    } else {
      console.log('‚úÖ Aucun doublon trouv√©');
    }

  } catch (error) {
    console.error('‚ùå Erreur:', error);
  } finally {
    await mongoose.disconnect();
  }
}

// Exporter les fonctions
module.exports = {
  cleanupDatabase,
  cleanDuplicatesOnly
};

// Ex√©cuter la fonction principale si le script est lanc√© directement
if (require.main === module) {
  const args = process.argv.slice(2);
  if (args.includes('--duplicates-only')) {
    cleanDuplicatesOnly();
  } else {
    cleanupDatabase();
  }
}