const mongoose = require('mongoose');
require('dotenv').config();

const BoilerData = require('./models/BoilerData');

async function analyzeSpecificFile() {
  try {
    console.log('üîå Connexion √† MongoDB...');
    await mongoose.connect(process.env.MONGODB_URI);
    console.log('‚úÖ Connect√© avec succ√®s\n');

    // Analyser un fichier sp√©cifique pour comprendre le probl√®me
    const filename = 'touch_20251026.csv';
    
    console.log(`üîç ANALYSE D√âTAILL√âE DU FICHIER: ${filename}`);
    console.log('=============================================');

    // Compter le nombre total d'entr√©es pour ce fichier
    const totalEntries = await BoilerData.countDocuments({ filename });
    console.log(`üìä Nombre total d'entr√©es en base: ${totalEntries.toLocaleString()}`);

    // Analyser les dates d'import
    const importAnalysis = await BoilerData.aggregate([
      { $match: { filename } },
      {
        $group: {
          _id: { 
            importDate: { $dateToString: { format: '%Y-%m-%d %H:%M:%S', date: '$importDate' } }
          },
          count: { $sum: 1 },
          minDataDate: { $min: '$date' },
          maxDataDate: { $max: '$date' }
        }
      },
      { $sort: { '_id.importDate': -1 } },
      { $limit: 10 }
    ]);

    console.log(`\nüìÖ TOP 10 des imports de ce fichier:`);
    importAnalysis.forEach((imp, index) => {
      console.log(`${index + 1}. Import le ${imp._id.importDate}: ${imp.count} entr√©es`);
      console.log(`   Donn√©es du ${imp.minDataDate.toLocaleDateString()} au ${imp.maxDataDate.toLocaleDateString()}`);
    });

    // V√©rifier s'il y a vraiment des doublons (m√™me date + heure)
    console.log(`\nüîç ANALYSE DES VRAIES DONN√âES:`);
    
    const duplicateDataCheck = await BoilerData.aggregate([
      { $match: { filename } },
      {
        $group: {
          _id: { 
            date: '$date',
            time: '$time'
          },
          count: { $sum: 1 },
          importDates: { $addToSet: '$importDate' }
        }
      },
      { $match: { count: { $gt: 1 } } },
      { $sort: { count: -1 } },
      { $limit: 5 }
    ]);

    if (duplicateDataCheck.length > 0) {
      console.log(`‚ùå ${duplicateDataCheck.length} moments avec des doublons d√©tect√©s:`);
      duplicateDataCheck.forEach(dup => {
        console.log(`   ${dup._id.date.toLocaleDateString()} ${dup._id.time}: ${dup.count} fois`);
        console.log(`   Import√© √†: ${dup.importDates.map(d => d.toLocaleString()).join(', ')}`);
      });
    } else {
      console.log(`‚úÖ Aucun doublon de donn√©es r√©elles d√©tect√©`);
      console.log(`   Le probl√®me est bien la r√©importation du m√™me fichier`);
    }

    // Voir quelques exemples de donn√©es
    console.log(`\nüìã EXEMPLES DE DONN√âES (premi√®res entr√©es):`);
    const sampleData = await BoilerData.find({ filename })
      .sort({ date: 1, time: 1 })
      .limit(5);
    
    sampleData.forEach((entry, index) => {
      console.log(`${index + 1}. ${entry.date.toLocaleDateString()} ${entry.time} - Temp: ${entry.outsideTemp}¬∞C - Import: ${entry.importDate ? entry.importDate.toLocaleString() : 'Non d√©fini'}`);
    });

    // Comparer avec un autre fichier
    console.log(`\nüîÑ COMPARAISON AVEC D'AUTRES FICHIERS:`);
    
    const fileComparison = await BoilerData.aggregate([
      {
        $group: {
          _id: '$filename',
          count: { $sum: 1 },
          uniqueImports: { $addToSet: '$importDate' }
        }
      },
      { $sort: { count: -1 } },
      { $limit: 5 }
    ]);

    fileComparison.forEach((file, index) => {
      const importsCount = file.uniqueImports.filter(d => d).length;
      const avgPerImport = importsCount > 0 ? Math.round(file.count / importsCount) : 0;
      console.log(`${index + 1}. ${file._id}: ${file.count} entr√©es, ${importsCount} imports, ~${avgPerImport} entr√©es/import`);
    });

  } catch (error) {
    console.error('‚ùå Erreur:', error);
  } finally {
    await mongoose.disconnect();
    console.log('\nüîå Connexion ferm√©e');
  }
}

analyzeSpecificFile();