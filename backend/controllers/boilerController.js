const BoilerData = require('../models/BoilerData');
const BoilerConfig = require('../models/BoilerConfig');
const csv = require('csv-parser');
const fs = require('fs');
const path = require('path');
const multer = require('multer');
const cron = require('node-cron');
const PORTS = require('../config/ports');

// Configuration de multer pour l'upload de fichiers
const storage = multer.diskStorage({
  destination: function (req, file, cb) {
    const uploadDir = path.join(process.cwd(), 'uploads');
    if (!fs.existsSync(uploadDir)) {
      fs.mkdirSync(uploadDir, { recursive: true });
    }
    cb(null, uploadDir);
  },
  filename: function (req, file, cb) {
    // Garder le nom original avec timestamp pour √©viter les conflits
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const originalName = Buffer.from(file.originalname, 'latin1').toString('utf8');
    cb(null, `${timestamp}_${originalName}`);
  }
});

const upload = multer({ 
  storage: storage,
  fileFilter: function (req, file, cb) {
    // Accepter seulement les fichiers CSV
    if (file.mimetype === 'text/csv' || 
        file.originalname.toLowerCase().endsWith('.csv')) {
      cb(null, true);
    } else {
      cb(new Error('Seuls les fichiers CSV sont autoris√©s'), false);
    }
  },
  limits: {
    fileSize: 10 * 1024 * 1024 // Limite √† 10MB
  }
});

// Fonction helper pour r√©cup√©rer la configuration depuis la base de donn√©es
async function getBoilerConfigData() {
  try {
    let config = await BoilerConfig.findOne({ configType: 'main' });
    
    // Si pas de configuration en base, cr√©er une configuration par d√©faut
    if (!config) {
      config = new BoilerConfig({
        nominalPower: 15,
        pelletsPerKWh: 0.2,
        importInterval: 1,
        configType: 'main'
      });
      await config.save();
      console.log('üîß Configuration par d√©faut cr√©√©e en base de donn√©es');
    }
    
    return config;
  } catch (error) {
    console.error('Erreur r√©cup√©ration config:', error);
    // Fallback en cas d'erreur
    return {
      nominalPower: 15,
      pelletsPerKWh: 0.2,
      importInterval: 1
    };
  }
}

// Fonction pour filtrer les donn√©es selon l'intervalle configur√©
function filterDataByInterval(data, intervalMinutes) {
  if (intervalMinutes <= 1) {
    return data; // Pas de filtrage si intervalle = 1 minute
  }

  const filtered = [];
  let lastTime = null;
  
  for (const entry of data) {
    // Cr√©er un timestamp complet avec date + time
    const [hours, minutes] = (entry.time || '00:00').split(':').map(n => parseInt(n) || 0);
    const entryTimestamp = new Date(entry.date);
    entryTimestamp.setHours(hours, minutes, 0, 0);
    
    if (!lastTime) {
      // Premi√®re entr√©e
      filtered.push(entry);
      lastTime = entryTimestamp;
    } else {
      // V√©rifier si assez de temps s'est √©coul√©
      const diffMinutes = (entryTimestamp - lastTime) / (1000 * 60);
      
      if (diffMinutes >= intervalMinutes) {
        filtered.push(entry);
        lastTime = entryTimestamp;
      }
    }
  }
  
  console.log(`üìä Filtrage temporel: ${data.length} ‚Üí ${filtered.length} entr√©es (intervalle: ${intervalMinutes}min)`);
  return filtered;
}

// Middleware d'upload
exports.uploadCSV = upload.single('csvFile');

// Importer un fichier CSV upload√©
exports.importUploadedCSV = async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'Aucun fichier upload√©' });
    }

    const csvPath = req.file.path;
    const originalFilename = req.file.originalname;

    const results = [];
    let lineCount = 0;

    // Lire et parser le CSV
    await new Promise((resolve, reject) => {
      fs.createReadStream(csvPath, { encoding: 'latin1' }) // Encoding pour caract√®res sp√©ciaux
        .pipe(csv({ separator: ';' }))
        .on('data', (data) => {
          lineCount++;
          
          // Convertir les donn√©es CSV vers notre format
          try {
            // La colonne s'appelle 'Datum ' avec un espace √† la fin
            const datumValue = data['Datum '] || data.Datum;
            const [day, month, year] = datumValue?.split('.') || [];
            
            // V√©rifier que les composants de la date existent
            if (!day || !month || !year) {
              return;
            }
            
            const dateStr = `${year}-${month.padStart(2, '0')}-${day.padStart(2, '0')}`;
            const date = new Date(dateStr);
            
            if (isNaN(date.getTime())) return;

            // G√©rer les diff√©rents formats de fichiers (ancien/nouveau)
            // Anciens fichiers: caract√®res ‚ñ° au lieu de ¬∞
            const runtime = parseFloat((data['PE1 Runtime[h]'] || data['PE1 Runtime[h] '])?.replace(',', '.')) || 0;
            const modulation = parseFloat((data['PE1 Modulation[%]'] || data['PE1 Modulation[%] '])?.replace(',', '.')) || 0;
            const boilerTemp = parseFloat((data['PE1 KT[¬∞C]'] || data['PE1 KT[¬∞C] '] || data['PE1 KT[‚ñ°C]'])?.replace(',', '.')) || 0;

            const boilerEntry = {
              date: date,
              time: (data['Zeit '] || data.Zeit)?.trim() || '',
              outsideTemp: parseFloat((data['AT [¬∞C]'] || data['AT [¬∞C] '] || data['AT [‚ñ°C]'])?.replace(',', '.')) || 0,
              outsideTempActive: parseFloat((data['ATakt [¬∞C]'] || data['ATakt [¬∞C] '] || data['ATakt [‚ñ°C]'])?.replace(',', '.')) || 0,
              heatingFlowTemp: parseFloat((data['HK1 VL Ist[¬∞C]'] || data['HK1 VL Ist[¬∞C] '] || data['HK1 VL Ist[‚ñ°C]'])?.replace(',', '.')) || 0,
              heatingFlowTempTarget: parseFloat((data['HK1 VL Soll[¬∞C]'] || data['HK1 VL Soll[¬∞C] '] || data['HK1 VL Soll[‚ñ°C]'])?.replace(',', '.')) || 0,
              boilerTemp: boilerTemp,
              boilerTempTarget: parseFloat((data['PE1 KT_SOLL[¬∞C]'] || data['PE1 KT_SOLL[¬∞C] '] || data['PE1 KT_SOLL[‚ñ°C]'])?.replace(',', '.')) || 0,
              modulation: modulation,
              fanSpeed: parseFloat((data['PE1 Luefterdrehzahl[%]'] || data['PE1 Luefterdrehzahl[%] '])?.replace(',', '.')) || 0,
              runtime: runtime,
              status: parseInt(data['PE1 Status'] || data['PE1 Status ']) || 0,
              hotWaterInTemp: parseFloat((data['WW1 EinT Ist[¬∞C]'] || data['WW1 EinT Ist[¬∞C] '] || data['WW1 EinT Ist[‚ñ°C]'])?.replace(',', '.')) || 0,
              hotWaterOutTemp: parseFloat((data['WW1 AusT Ist[¬∞C]'] || data['WW1 AusT Ist[¬∞C] '] || data['WW1 AusT Ist[‚ñ°C]'])?.replace(',', '.')) || 0,
              hotWaterTargetTemp: parseFloat((data['WW1 Soll[¬∞C]'] || data['WW1 Soll[¬∞C] '] || data['WW1 Soll[‚ñ°C]'])?.replace(',', '.')) || 0,
              hotWaterPumpStatus: parseInt(data['WW1 Pumpe'] || data['WW1 Pumpe ']) || 0,
              hotWaterStatus: parseInt(data['WW1 Status'] || data['WW1 Status ']) || 0,
              filename: originalFilename,
              fileSize: req.file.size // Taille du fichier en octets
            };

            // Crit√®re de validation adapt√© au format de fichier
            // Nouveau format: runtime > 0
            // Ancien format (sans runtime): accepter si les donn√©es semblent coh√©rentes
            // (temp√©rature chaudi√®re > 0 ET date valide) - la chaudi√®re peut √™tre √† l'arr√™t (modulation=0) mais avoir une temp√©rature de base
            // Si runtime n'existe pas (undefined), on valide uniquement sur la temp√©rature
            if (lineCount <= 5) {
              // Validation des donn√©es effectu√©e
            }
            const isValidEntry = (runtime !== undefined && runtime > 0) || 
                                 (runtime === 0 && boilerTemp > 0 && !isNaN(date.getTime())) ||
                                 (runtime === undefined && boilerTemp > 0 && !isNaN(date.getTime()));
            if (lineCount <= 5) {
              // Validation de la ligne effectu√©e
            }

            if (isValidEntry) {
              results.push(boilerEntry);
            }
          } catch (error) {
            console.error(`Erreur ligne ${lineCount}:`, error);
          }
        })
        .on('end', resolve)
        .on('error', reject);
    });

    console.log(`Fichier CSV lu: ${lineCount} lignes, ${results.length} entr√©es valides`);

    // R√©cup√©rer la configuration d'intervalle
    const config = await getBoilerConfigData();
    
    // Trier les donn√©es par date et heure pour un filtrage temporel correct
    results.sort((a, b) => {
      const timeA = new Date(a.date);
      const [hoursA, minutesA] = (a.time || '00:00').split(':').map(n => parseInt(n) || 0);
      timeA.setHours(hoursA, minutesA);
      
      const timeB = new Date(b.date);
      const [hoursB, minutesB] = (b.time || '00:00').split(':').map(n => parseInt(n) || 0);
      timeB.setHours(hoursB, minutesB);
      
      return timeA - timeB;
    });
    
    // Appliquer le filtrage temporel selon la configuration
    const filteredResults = filterDataByInterval(results, config.importInterval);
    
    console.log(`üìä Donn√©es apr√®s filtrage: ${filteredResults.length} entr√©es (intervalle: ${config.importInterval}min)`);

    // Supprimer les donn√©es existantes pour ce fichier
    await BoilerData.deleteMany({ filename: originalFilename });

    // Ins√©rer les nouvelles donn√©es filtr√©es
    if (filteredResults.length > 0) {
      await BoilerData.insertMany(filteredResults);
    }

    // Supprimer le fichier temporaire apr√®s import
    fs.unlinkSync(csvPath);

    res.json({
      success: true,
      message: `${filteredResults.length} entr√©es import√©es depuis ${originalFilename} (intervalle: ${config.importInterval}min)`,
      linesProcessed: lineCount,
      validEntries: filteredResults.length,
      originalEntries: results.length,
      filteredEntries: results.length - filteredResults.length,
      intervalMinutes: config.importInterval,
      filename: originalFilename
    });

  } catch (error) {
    console.error('Erreur import CSV:', error);
    res.status(500).json({ 
      error: 'Erreur lors de l\'import du CSV', 
      details: error.message 
    });
  }
};

// Importer un fichier CSV depuis le syst√®me de fichiers local
exports.importBoilerCSV = async (req, res) => {
  try {
    const { filename } = req.body;
    
    if (!filename) {
      return res.status(400).json({ error: 'Nom de fichier requis' });
    }

    // Chemin du fichier CSV (suppos√© dans le r√©pertoire racine du projet)
    const csvPath = path.join(process.cwd(), '..', filename);
    
    if (!fs.existsSync(csvPath)) {
      return res.status(404).json({ error: 'Fichier CSV non trouv√©' });
    }

    // Obtenir la taille du fichier
    const fileStats = fs.statSync(csvPath);
    const fileSize = fileStats.size;

    const results = [];
    let lineCount = 0;

    // Lire et parser le CSV (m√™me logique que pour les fichiers upload√©s)
    await new Promise((resolve, reject) => {
      fs.createReadStream(csvPath, { encoding: 'latin1' })
        .pipe(csv({ separator: ';' }))
        .on('data', (data) => {
          lineCount++;
          
          try {
            const [day, month, year] = data.Datum?.split('.') || [];
            const dateStr = `${year}-${month.padStart(2, '0')}-${day.padStart(2, '0')}`;
            const date = new Date(dateStr);
            
            if (isNaN(date.getTime())) {
              console.log(`Ligne ${lineCount}: Date invalide`, data.Datum);
              return;
            }

            // G√©rer les diff√©rents formats de fichiers (ancien/nouveau)
            // Anciens fichiers: caract√®res ‚ñ° au lieu de ¬∞
            const runtime = parseFloat(data['PE1 Runtime[h]']?.replace(',', '.')) || 0;
            const modulation = parseFloat((data['PE1 Modulation[%]'] || data['PE1 Modulation[%] '])?.replace(',', '.')) || 0;
            const boilerTemp = parseFloat((data['PE1 KT[¬∞C]'] || data['PE1 KT[‚ñ°C]'])?.replace(',', '.')) || 0;
            
            // Debug pour les anciens fichiers
            if (lineCount <= 5) {
              console.log(`Ligne ${lineCount} - Runtime: ${runtime}, Modulation: ${modulation}, BoilerTemp: ${boilerTemp}`);
            }
            
            const boilerEntry = {
              date: date,
              time: data.Zeit?.trim() || '',
              outsideTemp: parseFloat((data['AT [¬∞C]'] || data['AT [‚ñ°C]'])?.replace(',', '.')) || 0,
              outsideTempActive: parseFloat((data['ATakt [¬∞C]'] || data['ATakt [‚ñ°C]'])?.replace(',', '.')) || 0,
              heatingFlowTemp: parseFloat((data['HK1 VL Ist[¬∞C]'] || data['HK1 VL Ist[‚ñ°C]'])?.replace(',', '.')) || 0,
              heatingFlowTempTarget: parseFloat((data['HK1 VL Soll[¬∞C]'] || data['HK1 VL Soll[‚ñ°C]'])?.replace(',', '.')) || 0,
              boilerTemp: boilerTemp,
              boilerTempTarget: parseFloat((data['PE1 KT_SOLL[¬∞C]'] || data['PE1 KT_SOLL[‚ñ°C]'])?.replace(',', '.')) || 0,
              modulation: modulation,
              fanSpeed: parseFloat((data['PE1 Luefterdrehzahl[%]'] || data['PE1 Luefterdrehzahl[%] '])?.replace(',', '.')) || 0,
              runtime: runtime,
              status: parseInt(data['PE1 Status']) || 0,
              hotWaterInTemp: parseFloat((data['WW1 EinT Ist[¬∞C]'] || data['WW1 EinT Ist[‚ñ°C]'])?.replace(',', '.')) || 0,
              hotWaterOutTemp: parseFloat((data['WW1 AusT Ist[¬∞C]'] || data['WW1 AusT Ist[‚ñ°C]'])?.replace(',', '.')) || 0,
              hotWaterTargetTemp: parseFloat((data['WW1 Soll[¬∞C]'] || data['WW1 Soll[‚ñ°C]'])?.replace(',', '.')) || 0,
              hotWaterPumpStatus: parseInt(data['WW1 Pumpe']) || 0,
              hotWaterStatus: parseInt(data['WW1 Status']) || 0,
              filename: filename,
              fileSize: fileSize // Taille du fichier en octets
            };

            // Crit√®re de validation adapt√© au format de fichier
            // Nouveau format: runtime > 0
            // Ancien format (sans runtime): accepter si les donn√©es semblent coh√©rentes
            // (temp√©rature chaudi√®re > 0 ET date valide) - la chaudi√®re peut √™tre √† l'arr√™t (modulation=0) mais avoir une temp√©rature de base
            // Si runtime n'existe pas (undefined), on valide uniquement sur la temp√©rature
            if (lineCount <= 5) {
              // Validation des donn√©es Gmail effectu√©e
            }
            const isValidEntry = (runtime !== undefined && runtime > 0) || 
                                 (runtime === 0 && boilerTemp > 0 && !isNaN(date.getTime())) ||
                                 (runtime === undefined && boilerTemp > 0 && !isNaN(date.getTime()));
            if (lineCount <= 5) {
              // Validation Gmail de la ligne effectu√©e
            }
            
            if (isValidEntry) {
              results.push(boilerEntry);
            }
          } catch (error) {
            console.error(`Erreur ligne ${lineCount}:`, error);
          }
        })
        .on('end', resolve)
        .on('error', reject);
    });

    // R√©cup√©rer la configuration d'intervalle
    const config = await getBoilerConfigData();
    
    // Trier les donn√©es par date et heure pour un filtrage temporel correct
    results.sort((a, b) => {
      const timeA = new Date(a.date);
      const [hoursA, minutesA] = (a.time || '00:00').split(':').map(n => parseInt(n) || 0);
      timeA.setHours(hoursA, minutesA);
      
      const timeB = new Date(b.date);
      const [hoursB, minutesB] = (b.time || '00:00').split(':').map(n => parseInt(n) || 0);
      timeB.setHours(hoursB, minutesB);
      
      return timeA - timeB;
    });
    
    // Appliquer le filtrage temporel selon la configuration
    const filteredResults = filterDataByInterval(results, config.importInterval);

    // Supprimer les donn√©es existantes pour ce fichier
    await BoilerData.deleteMany({ filename });

    // Ins√©rer les nouvelles donn√©es filtr√©es
    if (filteredResults.length > 0) {
      await BoilerData.insertMany(filteredResults);
    }

    res.json({
      success: true,
      message: `${filteredResults.length} entr√©es import√©es depuis ${filename} (intervalle: ${config.importInterval}min)`,
      linesProcessed: lineCount,
      validEntries: filteredResults.length,
      originalEntries: results.length,
      intervalMinutes: config.importInterval
    });

  } catch (error) {
    console.error('Erreur import CSV:', error);
    res.status(500).json({ 
      error: 'Erreur lors de l\'import du CSV', 
      details: error.message 
    });
  }
};

// Calculer la consommation entre deux dates
exports.calculateConsumption = async (req, res) => {
  try {
    const { startDate, endDate } = req.query;
    
    // Calcul de la consommation pour la p√©riode demand√©e
    
    if (!startDate || !endDate) {
      return res.status(400).json({ 
        error: 'Dates de d√©but et fin requises' 
      });
    }

    // Convertir les dates en objets Date
    const startDateObj = new Date(startDate);
    const endDateObj = new Date(endDate);
    
    console.log('üìÖ Dates converties:', { 
      startDateObj: startDateObj.toISOString(), 
      endDateObj: endDateObj.toISOString() 
    });

    // V√©rifier qu'on a des donn√©es dans cette p√©riode
    const dataCount = await BoilerData.countDocuments({
      date: { $gte: startDateObj, $lte: endDateObj }
    });
    
    console.log(`üìä Nombre d'entr√©es trouv√©es pour la p√©riode: ${dataCount}`);

    // R√©cup√©rer la configuration depuis la base de donn√©es
    const config = await getBoilerConfigData();

    // R√©cup√©rer les donn√©es de runtime pour la p√©riode
    const startData = await BoilerData.findOne({
      date: { $gte: startDateObj }
    }).sort({ date: 1, time: 1 });

    const endData = await BoilerData.findOne({
      date: { $lte: endDateObj }
    }).sort({ date: -1, time: -1 });

    // Donn√©es de d√©but et fin r√©cup√©r√©es

    if (!startData || !endData) {
      // Cherchons les donn√©es disponibles pour diagnostic
      const firstData = await BoilerData.findOne().sort({ date: 1 });
      const lastData = await BoilerData.findOne().sort({ date: -1 });
      
      console.log('üìä Plage de donn√©es disponibles:', {
        first: firstData ? firstData.date : 'aucune',
        last: lastData ? lastData.date : 'aucune'
      });
      
      return res.status(404).json({ 
        error: 'Donn√©es insuffisantes pour la p√©riode',
        debug: {
          requestedPeriod: { startDate, endDate },
          availableData: {
            first: firstData ? firstData.date : null,
            last: lastData ? lastData.date : null,
            totalEntries: dataCount
          }
        }
      });
    }

    // Calculer la diff√©rence de runtime
    const runtimeHours = endData.runtime - startData.runtime;
    
    // Calculer la consommation moyenne de modulation sur la p√©riode
    const periodData = await BoilerData.aggregate([
      {
        $match: {
          date: { $gte: startDateObj, $lte: endDateObj },
          status: 99, // Chaudi√®re en fonctionnement
          modulation: { $gt: 0 } // Modulation active = combustion r√©elle
        }
      },
      {
        $group: {
          _id: null,
          avgModulation: { $avg: '$modulation' },
          count: { $sum: 1 },
          avgOutsideTemp: { $avg: '$outsideTemp' },
          avgFanSpeed: { $avg: '$fanSpeed' }
        }
      }
    ]);

    console.log('üìä Donn√©es p√©riode (status=99, modulation>0):', periodData[0] || 'aucune');

    const avgModulation = periodData[0]?.avgModulation || 60; // Default 60%
    const avgOutsideTemp = periodData[0]?.avgOutsideTemp || 10;

    // Calculer la consommation de pellets
    const effectivePower = config.nominalPower * (avgModulation / 100);
    const pelletConsumption = runtimeHours * effectivePower * config.pelletsPerKWh;

    // Statistiques d√©taill√©es
    const stats = await BoilerData.aggregate([
      {
        $match: {
          date: { $gte: startDateObj, $lte: endDateObj }
        }
      },
      {
        $group: {
          _id: { $dateToString: { format: '%Y-%m-%d', date: '$date' } },
          minTemp: { $min: '$outsideTemp' },
          maxTemp: { $max: '$outsideTemp' },
          avgTemp: { $avg: '$outsideTemp' },
          avgModulation: { $avg: '$modulation' },
          maxRuntime: { $max: '$runtime' },
          minRuntime: { $min: '$runtime' }
        }
      },
      { $sort: { _id: 1 } }
    ]);

    console.log(`üìà Stats quotidiennes g√©n√©r√©es: ${stats.length} jours`);

    res.json({
      period: {
        startDate,
        endDate,
        startRuntime: startData.runtime,
        endRuntime: endData.runtime,
        runtimeHours
      },
      consumption: {
        pelletKg: Math.round(pelletConsumption * 100) / 100,
        effectivePowerKW: Math.round(effectivePower * 10) / 10,
        avgModulationPercent: Math.round(avgModulation * 10) / 10
      },
      weather: {
        avgOutsideTempC: Math.round(avgOutsideTemp * 10) / 10
      },
      config: {
        nominalPower: config.nominalPower,
        pelletsPerKWh: config.pelletsPerKWh,
        importInterval: config.importInterval
      },
      dailyStats: stats
    });

  } catch (error) {
    console.error('Erreur calcul consommation:', error);
    res.status(500).json({ 
      error: 'Erreur lors du calcul de consommation',
      details: error.message 
    });
  }
};

// Obtenir les statistiques g√©n√©rales des donn√©es chaudi√®re
exports.getBoilerStats = async (req, res) => {
  try {
    // R√©cup√©rer la configuration depuis la base de donn√©es
    const config = await getBoilerConfigData();

    const stats = await BoilerData.aggregate([
      {
        $group: {
          _id: null,
          totalEntries: { $sum: 1 },
          minDate: { $min: '$date' },
          maxDate: { $max: '$date' },
          minRuntime: { $min: '$runtime' },
          maxRuntime: { $max: '$runtime' },
          filesImported: { $addToSet: '$filename' }
        }
      }
    ]);

    // Runtime total et consommation estim√©e
    const totalRuntimeHours = stats[0]?.maxRuntime || 0;
    const estimatedTotalConsumption = totalRuntimeHours * 
      config.nominalPower * 
      0.6 * // Modulation moyenne estim√©e
      config.pelletsPerKWh;

    res.json({
      stats: stats[0] || {},
      totalRuntimeHours,
      estimatedTotalConsumptionKg: Math.round(estimatedTotalConsumption),
      config: {
        nominalPower: config.nominalPower,
        pelletsPerKWh: config.pelletsPerKWh,
        importInterval: config.importInterval
      }
    });

  } catch (error) {
    console.error('Erreur stats chaudi√®re:', error);
    res.status(500).json({ 
      error: 'Erreur lors de la r√©cup√©ration des stats',
      details: error.message 
    });
  }
};

// Mettre √† jour la configuration de la chaudi√®re
// R√©cup√©rer la configuration de la chaudi√®re
exports.getBoilerConfig = async (req, res) => {
  try {
    const config = await getBoilerConfigData();
    
    res.json({
      success: true,
      config: {
        nominalPower: config.nominalPower,
        pelletsPerKWh: config.pelletsPerKWh,
        importInterval: config.importInterval,
        updatedAt: config.updatedAt
      }
    });

  } catch (error) {
    console.error('Erreur r√©cup√©ration config chaudi√®re:', error);
    res.status(500).json({ 
      success: false, 
      error: error.message 
    });
  }
};

// Mettre √† jour la configuration de la chaudi√®re
exports.updateBoilerConfig = async (req, res) => {
  try {
    const { nominalPower, pelletsPerKWh, importInterval } = req.body;
    
    // R√©cup√©rer ou cr√©er la configuration
    let config = await BoilerConfig.findOne({ configType: 'main' });
    
    if (!config) {
      config = new BoilerConfig({ configType: 'main' });
    }
    
    // Mettre √† jour les valeurs si fournies
    if (nominalPower !== undefined) {
      config.nominalPower = parseFloat(nominalPower);
    }
    if (pelletsPerKWh !== undefined) {
      config.pelletsPerKWh = parseFloat(pelletsPerKWh);
    }
    if (importInterval !== undefined) {
      config.importInterval = parseInt(importInterval);
      console.log(`üìä Pattern d'import mis √† jour: toutes les ${importInterval} minute(s)`);
    }

    // Sauvegarder en base
    await config.save();

    res.json({
      success: true,
      config: {
        nominalPower: config.nominalPower,
        pelletsPerKWh: config.pelletsPerKWh,
        importInterval: config.importInterval,
        updatedAt: config.updatedAt
      }
    });

  } catch (error) {
    console.error('Erreur config chaudi√®re:', error);
    res.status(500).json({ 
      error: 'Erreur lors de la mise √† jour de la config',
      details: error.message 
    });
  }
};

// Service d'auto-import
const autoImportService = require('../services/autoImportService');

// Contr√¥ler le service d'auto-import
exports.toggleAutoImport = async (req, res) => {
  try {
    const { enabled } = req.body;
    
    autoImportService.updateConfig({ autoImport: enabled });
    
    const status = autoImportService.getStatus();
    
    res.json({
      success: true,
      message: enabled ? 'Auto-import activ√©' : 'Auto-import d√©sactiv√©',
      status
    });
  } catch (error) {
    console.error('Erreur toggle auto-import:', error);
    res.status(500).json({ 
      error: 'Erreur lors du toggle auto-import',
      details: error.message 
    });
  }
};

// Obtenir le statut du service d'auto-import
exports.getAutoImportStatus = async (req, res) => {
  try {
    const status = autoImportService.getStatus();
    res.json(status);
  } catch (error) {
    console.error('Erreur statut auto-import:', error);
    res.status(500).json({ 
      error: 'Erreur lors de la r√©cup√©ration du statut',
      details: error.message 
    });
  }
};

// V√©rifier manuellement les nouveaux fichiers
exports.checkForNewFiles = async (req, res) => {
  try {
    await autoImportService.checkForNewFiles();
    res.json({
      success: true,
      message: 'V√©rification termin√©e'
    });
  } catch (error) {
    console.error('Erreur v√©rification fichiers:', error);
    res.status(500).json({ 
      error: 'Erreur lors de la v√©rification',
      details: error.message 
    });
  }
};

// Configuration Gmail
exports.getGmailConfig = async (req, res) => {
  try {
    const status = await autoImportService.initializeGmail();
    
    // Recharger la configuration pour s'assurer qu'elle est √† jour
    await autoImportService.loadGmailConfig();
    
    console.log('üìß Configuration Gmail r√©cup√©r√©e:', autoImportService.config.gmail);
    
    res.json({
      configured: status.configured,
      config: autoImportService.config.gmail,
      status: status
    });
  } catch (error) {
    console.error('Erreur config Gmail:', error);
    res.status(500).json({ error: error.message });
  }
};

exports.updateGmailConfig = async (req, res) => {
  try {
    const { enabled, sender, subject, senders } = req.body;
    
    // G√©rer la migration de l'ancien format vers le nouveau
    let sendersArray = senders;
    if (!sendersArray && sender) {
      // Migration de l'ancien format
      sendersArray = [sender];
    }
    if (!sendersArray || sendersArray.length === 0) {
      sendersArray = [''];
    }
    
    console.log('üìß Donn√©es re√ßues pour mise √† jour Gmail:', { enabled, sender, senders: sendersArray, subject });
    
    const updatedConfig = await autoImportService.updateGmailConfig({
      enabled: enabled !== undefined ? enabled : autoImportService.config.gmail?.enabled,
      senders: sendersArray,
      subject: subject || autoImportService.config.gmail?.subject
    });
    
    console.log('‚úÖ Configuration Gmail sauvegard√©e:', updatedConfig.toObject ? updatedConfig.toObject() : updatedConfig);
    
    res.json({
      success: true,
      message: 'Configuration Gmail mise √† jour et sauvegard√©e',
      config: updatedConfig.toObject ? updatedConfig.toObject() : updatedConfig
    });
  } catch (error) {
    console.error('Erreur mise √† jour Gmail:', error);
    res.status(500).json({ error: error.message });
  }
};

// Configuration d'import
exports.getImportConfig = async (req, res) => {
  try {
    const GmailConfig = require('../models/GmailConfig');
    const config = await GmailConfig.getConfig();
    
    res.json({
      success: true,
      config: {
        senderAddresses: config.senders || [],
        subjectKeywords: [config.subject || 'okofen'],
        importIntervals: 1, // Valeur par d√©faut
        cronSchedule: config.cronSchedule || '0 8 * * *',
        cronEnabled: config.enabled || false,
        overwriteFiles: false // Valeur par d√©faut
      }
    });
  } catch (error) {
    console.error('Erreur r√©cup√©ration config import:', error);
    res.status(500).json({ error: error.message });
  }
};

exports.saveImportConfig = async (req, res) => {
  try {
    const { senderAddresses, subjectKeywords, cronSchedule, cronEnabled } = req.body;
    
    const GmailConfig = require('../models/GmailConfig');
    const config = await GmailConfig.updateConfig({
      senders: senderAddresses || [],
      subject: subjectKeywords && subjectKeywords.length > 0 ? subjectKeywords[0] : 'okofen',
      cronSchedule: cronSchedule || '0 8 * * *',
      enabled: cronEnabled || false
    });
    
    // Mettre √† jour aussi le service d'auto-import
    await autoImportService.loadGmailConfig();
    
    res.json({
      success: true,
      message: 'Configuration d\'import sauvegard√©e avec succ√®s',
      config: config.toObject()
    });
  } catch (error) {
    console.error('Erreur sauvegarde config import:', error);
    res.status(500).json({ error: error.message });
  }
};

// Authentification Gmail
exports.getGmailAuthUrl = async (req, res) => {
  try {
    const authUrl = await autoImportService.gmailService.getAuthUrl();
    res.json({ authUrl });
  } catch (error) {
    console.error('Erreur URL auth Gmail:', error);
    res.status(500).json({ error: error.message });
  }
};

exports.handleGmailAuthCallback = async (req, res) => {
  try {
    const { code } = req.query;
    if (!code) {
      return res.status(400).json({ error: 'Code d\'autorisation manquant' });
    }

    const result = await autoImportService.gmailService.exchangeCodeForToken(code);
    
    // R√©initialiser le service avec le nouveau token
    await autoImportService.initializeGmail();
    
    // Rediriger vers l'interface frontend selon l'environnement
    const isProduction = process.env.NODE_ENV === 'production' || 
                         process.env.VERCEL || 
                         process.cwd().includes('/home/pelletsfun/') ||
                         process.env.PM2_HOME;
    
    const frontendUrl = isProduction ? 'https://pelletsfun.harmonixe.fr' : 'http://localhost:3000';
    console.log(`üîó Redirection callback (${isProduction ? 'PRODUCTION' : 'LOCAL'}): ${frontendUrl}/?gmail-auth=success`);
    
    res.redirect(`${frontendUrl}/?gmail-auth=success`);
  } catch (error) {
    console.error('Erreur callback Gmail:', error);
    
    // Rediriger vers l'interface frontend selon l'environnement  
    const isProduction = process.env.NODE_ENV === 'production' || 
                         process.env.VERCEL || 
                         process.cwd().includes('/home/pelletsfun/') ||
                         process.env.PM2_HOME;
    
    const frontendUrl = isProduction ? 'https://pelletsfun.harmonixe.fr' : 'http://localhost:3000';
    console.log(`üîó Redirection erreur (${isProduction ? 'PRODUCTION' : 'LOCAL'}): ${frontendUrl}/?gmail-auth=error`);
    
    res.redirect(`${frontendUrl}/?gmail-auth=error`);
  }
};

// Traitement manuel des emails Gmail (version optimis√©e)
exports.processGmailEmails = async (req, res) => {
  try {
    // Utiliser le nouveau service Gmail optimis√© directement
    const GmailService = require('../services/gmailService');
    const gmailService = new GmailService();
    await gmailService.initializeAuth();
    
    // R√©cup√©rer la configuration Gmail existante
    const GmailConfig = require('../models/GmailConfig');
    const config = await GmailConfig.getConfig();
    
    // Traitement avec la logique optimis√©e
    const result = await gmailService.processOkofenEmails({
      sender: config.senders && config.senders.filter(s => s.trim()).length > 0 ? config.senders.filter(s => s.trim()) : null,
      subject: config.subject || 'okofen',
      downloadPath: require('path').join(process.cwd(), 'backend', 'auto-downloads'),
      processCallback: async (filePath, context) => {
        // Import automatique du fichier CSV avec l'autoImportService existant
        try {
          const autoImportService = require('../services/autoImportService');
          const importResult = await autoImportService.importCSVFile(filePath, require('path').basename(filePath));
          console.log(`üìä Import CSV r√©ussi: ${context.attachment.filename} - ${importResult.validEntries} entr√©es`);
          return importResult;
        } catch (importError) {
          console.error(`‚ùå Erreur import CSV ${context.attachment.filename}:`, importError.message);
          throw importError;
        }
      },
      markAsProcessed: true,
      labelProcessed: 'PelletsFun-Trait√©'
    });

    // Nettoyage automatique des anciens enregistrements en arri√®re-plan
    gmailService.cleanupOldProcessedEmails().catch(err => 
      console.error('Erreur nettoyage (non bloquante):', err.message)
    );

    res.json({
      success: true,
      message: `‚úÖ Traitement optimis√© termin√©: ${result.downloaded} fichiers t√©l√©charg√©s, ${result.processed} trait√©s`,
      downloaded: result.downloaded,
      processed: result.processed,
      errors: result.errors
    });

  } catch (error) {
    console.error('‚ùå Erreur traitement Gmail optimis√©:', error);
    res.status(500).json({ 
      success: false,
      error: error.message 
    });
  }
};

// Configuration du traitement automatique quotidien
exports.getCronStatus = async (req, res) => {
  try {
    const status = {
      isActive: autoImportService.cronJob ? true : false,
      schedule: autoImportService.config.cronSchedule,
      gmailEnabled: autoImportService.config.gmail?.enabled || false,
      lastRun: autoImportService.stats.lastRun,
      stats: autoImportService.stats
    };
    res.json(status);
  } catch (error) {
    console.error('Erreur statut cron:', error);
    res.status(500).json({ error: error.message });
  }
};

exports.updateCronSchedule = async (req, res) => {
  try {
    const { schedule, enabled } = req.body;
    
    // Valider le format cron
    if (schedule && !cron.validate(schedule)) {
      return res.status(400).json({ error: 'Format de planning invalide' });
    }
    
    // Arr√™ter l'ancien cron s'il existe
    if (autoImportService.cronJob) {
      await autoImportService.stopCronJob();
    }
    
    // Mettre √† jour la configuration
    if (schedule) {
      autoImportService.config.cronSchedule = schedule;
    }
    
    // Sauvegarder la configuration en base
    await autoImportService.saveCronConfigToDB(
      autoImportService.config.cronSchedule, 
      enabled || false
    );
    
    // D√©marrer le nouveau cron si activ√©
    if (enabled) {
      await autoImportService.startCronJob();
    }
    
    res.json({
      success: true,
      message: 'Planning mis √† jour et sauvegard√©',
      schedule: autoImportService.config.cronSchedule,
      active: autoImportService.cronJob ? true : false
    });
  } catch (error) {
    console.error('Erreur mise √† jour cron:', error);
    res.status(500).json({ error: error.message });
  }
};

exports.startCronJob = async (req, res) => {
  try {
    await autoImportService.startCronJob();
    res.json({
      success: true,
      message: 'Traitement automatique d√©marr√© et sauvegard√©',
      schedule: autoImportService.config.cronSchedule
    });
  } catch (error) {
    console.error('Erreur d√©marrage cron:', error);
    res.status(500).json({ error: error.message });
  }
};

exports.stopCronJob = async (req, res) => {
  try {
    await autoImportService.stopCronJob();
    res.json({
      success: true,
      message: 'Traitement automatique arr√™t√©'
    });
  } catch (error) {
    console.error('Erreur arr√™t cron:', error);
    res.status(500).json({ error: error.message });
  }
};

// D√©clencher manuellement l'import des emails
exports.triggerManualImport = async (req, res) => {
  try {
    console.log('üîÑ D√©clenchement manuel de l\'import demand√©');
    
    // R√©cup√©rer les param√®tres de p√©riode, exp√©diteurs et options d'√©crasement depuis la requ√™te
    const { dateFrom, dateTo, senders, overwriteExisting } = req.body;
    
    console.log('üìÖ Param√®tres de p√©riode:', { dateFrom, dateTo });
    console.log('üìß Exp√©diteurs:', senders);
    console.log('üîÑ √âcraser fichiers existants:', overwriteExisting || false);

    // Cr√©er une t√¢che asynchrone
    const taskManager = require('../services/taskManager');
    const taskDescription = `Import Gmail ${dateFrom || 'd√©but'} ‚Üí ${dateTo || 'fin'}${overwriteExisting ? ' (√©crasement)' : ''}`;
    const task = taskManager.createTask('gmail_import', taskDescription);

    // R√©pondre imm√©diatement avec l'ID de t√¢che
    res.json({
      success: true,
      message: 'Import d√©marr√© en arri√®re-plan',
      taskId: task.id,
      task: {
        id: task.id,
        description: task.description,
        status: task.status,
        progress: task.progress,
        details: task.details
      }
    });

    // D√©marrer le traitement asynchrone
    setImmediate(() => processGmailImportAsync(task.id, { dateFrom, dateTo, senders, overwriteExisting }));

  } catch (error) {
    console.error('‚ùå Erreur cr√©ation t√¢che import manuel:', error);
    res.status(500).json({
      success: false,
      error: error.message,
      stack: process.env.NODE_ENV === 'development' ? error.stack : undefined
    });
  }
};

// Obtenir le statut du service d'import
exports.getImportStatus = async (req, res) => {
  try {
    const autoImportService = require('../services/autoImportService');
    
    // Obtenir le statut du service
    const serviceStatus = autoImportService.getStatus();
    const serviceStats = autoImportService.stats;
    
    // V√©rifier la configuration Gmail
    const gmailStatus = await autoImportService.initializeGmail();
    
    // Statistiques de la base de donn√©es
    const dbStats = {
      totalEntries: await BoilerData.countDocuments(),
      totalFiles: (await BoilerData.distinct('filename')).length,
      lastEntry: await BoilerData.findOne().sort({ createdAt: -1 }),
      oldestEntry: await BoilerData.findOne().sort({ createdAt: 1 })
    };
    
    res.json({
      success: true,
      service: {
        isWatching: serviceStatus.isWatching,
        cronActive: serviceStatus.cronActive,
        gmailConfigured: gmailStatus.configured,
        gmailError: gmailStatus.error || null
      },
      stats: {
        filesProcessed: serviceStats.filesProcessed || 0,
        errors: serviceStats.errors || 0,
        lastRun: serviceStats.lastRun || null,
        totalFiles: serviceStats.totalFiles || 0,
        successfulFiles: serviceStats.successfulFiles || 0
      },
      database: dbStats,
      config: {
        emailSettings: serviceStatus.config.gmail || {},
        preventDuplicates: true
      }
    });
    
  } catch (error) {
    console.error('‚ùå Erreur r√©cup√©ration statut:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
};

exports.getImportHistory = async (req, res) => {
  try {
    // R√©cup√©rer les fichiers uniques avec leurs statistiques
    const fileStats = await BoilerData.aggregate([
      {
        $group: {
          _id: "$filename",
          totalEntries: { $sum: 1 },
          firstImport: { $min: "$createdAt" },
          lastImport: { $max: "$createdAt" },
          fileSize: { $first: "$fileSize" }, // R√©cup√©rer la taille stock√©e en base
          dateRange: {
            $addToSet: {
              $dateToString: {
                format: "%Y-%m-%d",
                date: "$date"
              }
            }
          },
          avgOutsideTemp: { $avg: "$outsideTemp" },
          totalRuntime: { 
            $sum: { 
              $cond: [{ $gt: ["$runtime", 0] }, 1, 0] 
            } 
          },
          // Nouvelles statistiques pour d√©tection arr√™t/marche
          avgBoilerTemp: { $avg: "$boilerTemp" },
          maxBoilerTemp: { $max: "$boilerTemp" },
          avgModulation: { $avg: "$modulation" },
          maxRuntime: { $max: "$runtime" },
          minRuntime: { $min: "$runtime" },
          avgFanSpeed: { $avg: "$fanSpeed" },
          // Compter les entr√©es avec diff√©rents statuts
          activeEntries: { 
            $sum: { 
              $cond: [
                { $and: [
                  { $gt: ["$boilerTemp", 40] },
                  { $gt: ["$modulation", 0] }
                ]}, 
                1, 0 
              ] 
            } 
          },
          // Statuts les plus fr√©quents
          statusStats: { $push: "$status" }
        }
      },
      {
        $project: {
          filename: "$_id",
          totalEntries: 1,
          firstImport: 1,
          lastImport: 1,
          fileSize: 1, // Inclure la taille du fichier
          dateRange: {
            $reduce: {
              input: "$dateRange",
              initialValue: { min: null, max: null },
              in: {
                min: {
                  $cond: [
                    { $or: [{ $eq: ["$$value.min", null] }, { $lt: ["$$this", "$$value.min"] }] },
                    "$$this",
                    "$$value.min"
                  ]
                },
                max: {
                  $cond: [
                    { $or: [{ $eq: ["$$value.max", null] }, { $gt: ["$$this", "$$value.max"] }] },
                    "$$this",
                    "$$value.max"
                  ]
                }
              }
            }
          },
          avgOutsideTemp: { $round: ["$avgOutsideTemp", 1] },
          totalRuntime: 1,
          // Nouvelles stats format√©es
          avgBoilerTemp: { $round: ["$avgBoilerTemp", 1] },
          maxBoilerTemp: { $round: ["$maxBoilerTemp", 1] },
          avgModulation: { $round: ["$avgModulation", 1] },
          runtimeRange: {
            min: "$minRuntime",
            max: "$maxRuntime"
          },
          avgFanSpeed: { $round: ["$avgFanSpeed", 0] },
          activeEntries: 1,
          activityRate: { 
            $round: [{ 
              $multiply: [
                { $divide: ["$activeEntries", "$totalEntries"] }, 
                100
              ] 
            }, 1] 
          },
          _id: 0
        }
      },
      {
        $sort: { filename: -1 }
      }
    ]);

    // Enrichir les stats avec les informations format√©es
    const enrichedStats = fileStats.map(stat => {
      // V√©rifier si le fichier existe dans les dossiers de t√©l√©chargement
      const possiblePaths = [
        path.join(process.cwd(), 'auto-downloads', stat.filename),
        path.join(process.cwd(), stat.filename),
        path.join(process.cwd(), 'uploads', stat.filename)
      ];

      let fileExists = false;
      let filePath = null;

      for (const testPath of possiblePaths) {
        if (fs.existsSync(testPath)) {
          fileExists = true;
          filePath = testPath;
          break;
        }
      }

      // Utiliser la taille stock√©e en base, sinon fallback sur le fichier physique
      let finalFileSize = 0;
      if (stat.fileSize && stat.fileSize > 0) {
        finalFileSize = Math.round(stat.fileSize / 1024); // Convertir en KB
      } else if (fileExists && filePath) {
        // Fallback pour les anciens imports sans taille stock√©e
        try {
          finalFileSize = Math.round(fs.statSync(filePath).size / 1024);
        } catch (e) {
          finalFileSize = 0;
        }
      }

      return {
        ...stat,
        fileExists,
        fileSize: finalFileSize, // KB
        filePath: fileExists ? filePath : null,
        status: stat.totalEntries > 0 ? 'success' : 'empty'
      };
    });

    res.json({
      success: true,
      files: enrichedStats,
      totalFiles: enrichedStats.length,
      totalEntries: enrichedStats.reduce((sum, f) => sum + f.totalEntries, 0)
    });

  } catch (error) {
    console.error('Erreur r√©cup√©ration historique:', error);
    res.status(500).json({ error: error.message });
  }
};

// Obtenir le statut d'une t√¢che sp√©cifique
exports.getTaskStatus = async (req, res) => {
  try {
    const { taskId } = req.params;
    const taskManager = require('../services/taskManager');
    
    const task = taskManager.getTask(taskId);
    
    if (!task) {
      return res.status(404).json({
        success: false,
        error: 'T√¢che introuvable'
      });
    }

    res.json({
      success: true,
      task: {
        id: task.id,
        type: task.type,
        description: task.description,
        status: task.status,
        progress: task.progress,
        startTime: task.startTime,
        endTime: task.endTime,
        duration: task.duration,
        details: task.details,
        result: task.result,
        error: task.error
      }
    });

  } catch (error) {
    console.error('‚ùå Erreur r√©cup√©ration statut t√¢che:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
};

// Obtenir les logs d'une t√¢che sp√©cifique
exports.getTaskLogs = async (req, res) => {
  try {
    const { taskId } = req.params;
    const taskManager = require('../services/taskManager');
    
    const task = taskManager.getTask(taskId);
    
    if (!task) {
      return res.status(404).json({
        success: false,
        error: 'T√¢che introuvable'
      });
    }

    res.json({
      success: true,
      logs: task.logs || []
    });

  } catch (error) {
    console.error('‚ùå Erreur r√©cup√©ration logs t√¢che:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
};

// Obtenir toutes les t√¢ches actives
exports.getActiveTasks = async (req, res) => {
  try {
    const taskManager = require('../services/taskManager');
    const tasks = taskManager.getUserTasks();
    
    const activeTasks = tasks.map(task => ({
      id: task.id,
      type: task.type,
      description: task.description,
      status: task.status,
      progress: task.progress,
      startTime: task.startTime,
      endTime: task.endTime,
      duration: task.duration,
      details: task.details
    }));

    res.json({
      success: true,
      tasks: activeTasks,
      stats: taskManager.getStats()
    });

  } catch (error) {
    console.error('‚ùå Erreur r√©cup√©ration t√¢ches actives:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
};

// Supprimer un import sp√©cifique
exports.deleteImport = async (req, res) => {
  try {
    const { filename } = req.params;
    
    if (!filename) {
      return res.status(400).json({ error: 'Nom de fichier requis' });
    }

    console.log(`üóëÔ∏è Suppression de l'import: ${filename}`);

    // V√©rifier combien d'entr√©es seront supprim√©es
    const entryCount = await BoilerData.countDocuments({ filename });
    
    if (entryCount === 0) {
      return res.status(404).json({ 
        error: `Aucune donn√©e trouv√©e pour le fichier "${filename}"` 
      });
    }

    // Supprimer toutes les entr√©es de ce fichier
    const deleteResult = await BoilerData.deleteMany({ filename });

    // Supprimer le fichier physique s'il existe
    const possiblePaths = [
      path.join(process.cwd(), 'auto-downloads', filename),
      path.join(process.cwd(), filename),
      path.join(process.cwd(), 'uploads', filename)
    ];

    let fileDeleted = false;
    for (const testPath of possiblePaths) {
      if (fs.existsSync(testPath)) {
        try {
          fs.unlinkSync(testPath);
          fileDeleted = true;
          console.log(`üìÅ Fichier physique supprim√©: ${testPath}`);
          break;
        } catch (error) {
          console.warn(`‚ö†Ô∏è Impossible de supprimer le fichier: ${testPath}`, error.message);
        }
      }
    }

    console.log(`‚úÖ Suppression termin√©e: ${deleteResult.deletedCount} entr√©es supprim√©es`);

    res.json({
      success: true,
      message: `Import "${filename}" supprim√© avec succ√®s`,
      deletedEntries: deleteResult.deletedCount,
      fileDeleted
    });

  } catch (error) {
    console.error('‚ùå Erreur suppression import:', error);
    res.status(500).json({ 
      error: `Erreur lors de la suppression: ${error.message}` 
    });
  }
};

/**
 * Traitement asynchrone de l'import Gmail
 */
async function processGmailImportAsync(taskId, params) {
  const taskManager = require('../services/taskManager');
  
  try {
    const { dateFrom, dateTo, senders, overwriteExisting } = params;
    
    // √âtape 1: Initialisation
    taskManager.updateTaskStatus(taskId, 'running', 0, { 
      currentStep: 'Initialisation des services...' 
    });
    taskManager.addTaskLog(taskId, 'info', 'D√©marrage du traitement asynchrone');

    // Importer les services n√©cessaires
    const autoImportService = require('../services/autoImportService');
    const GmailService = require('../services/gmailService');
    const GmailConfig = require('../models/GmailConfig');

    // √âtape 2: Statistiques initiales
    taskManager.updateTaskStatus(taskId, 'running', 5, { 
      currentStep: 'Collecte des statistiques initiales...' 
    });

    const statsBefore = await BoilerData.countDocuments();
    const filesBefore = await BoilerData.distinct('filename');
    
    taskManager.addTaskLog(taskId, 'info', `√âtat avant import: ${statsBefore} entr√©es, ${filesBefore.length} fichiers`);

    // √âtape 3: Configuration Gmail
    taskManager.updateTaskStatus(taskId, 'running', 10, { 
      currentStep: 'Configuration du service Gmail...' 
    });

    const gmailService = new GmailService();
    const gmailInitResult = await gmailService.initialize();
    
    if (!gmailInitResult.configured) {
      throw new Error(`Service Gmail non configur√©: ${gmailInitResult.error}`);
    }

    const config = await GmailConfig.getConfig();
    taskManager.addTaskLog(taskId, 'info', 'Service Gmail initialis√© avec succ√®s');

    // √âtape 4: Pr√©paration des param√®tres
    taskManager.updateTaskStatus(taskId, 'running', 15, { 
      currentStep: 'Pr√©paration des param√®tres d\'import...' 
    });

    const importParams = {};
    if (dateFrom || dateTo) {
      importParams.period = {
        dateFrom: dateFrom ? new Date(dateFrom) : null,
        dateTo: dateTo ? new Date(dateTo) : null
      };
    }

    const gmailOptions = {
      subject: config.subject || 'okofen',
      downloadPath: require('path').join(process.cwd(), 'backend', 'auto-downloads'),
      processCallback: async (filePath, context) => {
        // Callback avec mise √† jour du progr√®s
        taskManager.updateTaskStatus(taskId, 'running', null, {
          currentStep: `Import CSV: ${context.attachment.filename}...`,
          importedFiles: (taskManager.getTask(taskId).details.importedFiles || 0) + 1
        });
        
        try {
          const importResult = await autoImportService.importCSVFile(filePath, require('path').basename(filePath));
          taskManager.addTaskLog(taskId, 'success', `Import CSV r√©ussi: ${context.attachment.filename} - ${importResult.validEntries} entr√©es`);
          return importResult;
        } catch (importError) {
          taskManager.addTaskLog(taskId, 'error', `Erreur import CSV ${context.attachment.filename}: ${importError.message}`);
          throw importError;
        }
      },
      markAsProcessed: true,
      labelProcessed: 'PelletsFun-Trait√©',
      overwriteExisting: overwriteExisting || false
    };

    // Configuration de la p√©riode
    if (importParams.period) {
      if (importParams.period.dateFrom) {
        gmailOptions.dateFrom = importParams.period.dateFrom.toISOString().split('T')[0];
      }
      if (importParams.period.dateTo) {
        gmailOptions.dateTo = importParams.period.dateTo.toISOString().split('T')[0];
      }
    }

    // Configuration des exp√©diteurs
    if (senders && senders.length > 0) {
      gmailOptions.sender = senders;
    } else if (config.senders && config.senders.filter(s => s.trim()).length > 0) {
      gmailOptions.sender = config.senders.filter(s => s.trim());
    }

    // √âtape 5: Recherche pr√©liminaire pour obtenir le total
    taskManager.updateTaskStatus(taskId, 'running', 20, { 
      currentStep: 'Recherche des emails Gmail...' 
    });

    // D'abord, faire une recherche pour obtenir le nombre total
    const searchResult = await gmailService.searchOkofenEmails(gmailOptions);
    
    // Compter le nombre total de fichiers √† traiter
    let totalFiles = 0;
    if (searchResult.emails && searchResult.emails.length > 0) {
      totalFiles = searchResult.emails.reduce((total, email) => {
        return total + email.attachments.length;
      }, 0);
      
      taskManager.updateTaskStatus(taskId, 'running', 25, { 
        currentStep: `${searchResult.totalFound} emails trouv√©s, ${totalFiles} fichiers √† traiter...`,
        totalEmails: searchResult.totalFound,
        totalFiles: totalFiles,
        processedFiles: 0,
        pagesProcessed: searchResult.pagesProcessed || 1
      });
      taskManager.addTaskLog(taskId, 'info', `Recherche termin√©e: ${searchResult.totalFound} emails trouv√©s, ${totalFiles} fichiers CSV √† traiter sur ${searchResult.pagesProcessed || 1} page(s)`);
    } else {
      taskManager.updateTaskStatus(taskId, 'running', 100, { 
        currentStep: 'Aucun fichier √† traiter.' 
      });
      taskManager.addTaskLog(taskId, 'info', 'Aucun email avec fichiers CSV trouv√©');
      
      // Terminer la t√¢che imm√©diatement s'il n'y a pas de fichiers
      const emptyResult = {
        entriesBefore: statsBefore,
        entriesAfter: statsBefore,
        newEntries: 0,
        filesBefore: filesBefore.length,
        filesAfter: filesBefore.length,
        newFiles: 0,
        importDetails: { downloaded: 0, processed: 0, errors: [] }
      };
      taskManager.completeTask(taskId, emptyResult);
      return;
    }

    // √âtape 6: Traitement des emails avec callback de progression
    taskManager.updateTaskStatus(taskId, 'running', 30, { 
      currentStep: 'Traitement et t√©l√©chargement des pi√®ces jointes...' 
    });

    // Modifier les options pour inclure un callback de progression par fichier
    const originalCallback = gmailOptions.processCallback;
    let processedFiles = 0;
    let downloadedCount = 0;
    
    gmailOptions.processCallback = async (filePath, context) => {
      processedFiles++;
      
      // Calculer le pourcentage bas√© sur les fichiers trait√©s (30% √† 85% de la progression totale)
      const fileProgress = Math.round(30 + (processedFiles / totalFiles) * 55);
      
      taskManager.updateTaskStatus(taskId, 'running', fileProgress, {
        currentStep: `Import CSV: ${context.attachment.filename} (${processedFiles}/${totalFiles})...`,
        processedFiles: processedFiles,
        totalFiles: totalFiles,
        downloadedFiles: processedFiles // Mise √† jour du nombre de t√©l√©chargements
      });
      
      // Appeler le callback original s'il existe
      if (originalCallback) {
        try {
          const result = await originalCallback(filePath, context);
          
          // Mettre √† jour le nombre de fichiers import√©s
          taskManager.updateTaskStatus(taskId, 'running', fileProgress, {
            currentStep: `Import CSV: ${context.attachment.filename} termin√© (${processedFiles}/${totalFiles})`,
            processedFiles: processedFiles,
            totalFiles: totalFiles,
            downloadedFiles: processedFiles,
            importedFiles: processedFiles
          });
          
          return result;
        } catch (importError) {
          taskManager.addTaskLog(taskId, 'error', `Erreur import ${context.attachment.filename}: ${importError.message}`);
          throw importError;
        }
      }
    };

    // Traitement direct des emails d√©j√† trouv√©s pour √©viter une double recherche
    let importResult;
    if (searchResult.emails && searchResult.emails.length > 0) {
      // Utiliser les emails d√©j√† trouv√©s au lieu de refaire une recherche
      importResult = await gmailService.processEmailsDirectly(searchResult.emails, gmailOptions);
    } else {
      // Fallback: utiliser la m√©thode normale si searchResult ne contient pas les emails
      importResult = await gmailService.processOkofenEmails(gmailOptions);
    }

    // √âtape 7: Nettoyage et statistiques finales
    taskManager.updateTaskStatus(taskId, 'running', 90, { 
      currentStep: 'Finalisation et statistiques...' 
    });

    // Nettoyage en arri√®re-plan
    gmailService.cleanupOldProcessedEmails().catch(err => 
      taskManager.addTaskLog(taskId, 'warn', `Nettoyage (non bloquant): ${err.message}`)
    );

    // Statistiques finales
    const statsAfter = await BoilerData.countDocuments();
    const filesAfter = await BoilerData.distinct('filename');
    const newEntries = statsAfter - statsBefore;
    const newFiles = filesAfter.length - filesBefore.length;

    taskManager.addTaskLog(taskId, 'info', `√âtat apr√®s import: ${statsAfter} entr√©es, ${filesAfter.length} fichiers`);
    taskManager.addTaskLog(taskId, 'success', `Import termin√©: +${newEntries} entr√©es, +${newFiles} fichiers`);

    // R√©sultat final
    const finalResult = {
      entriesBefore: statsBefore,
      entriesAfter: statsAfter,
      newEntries: newEntries,
      filesBefore: filesBefore.length,
      filesAfter: filesAfter.length,
      newFiles: newFiles,
      importDetails: {
        downloaded: importResult.downloaded || 0,
        processed: importResult.processed || 0,
        errors: importResult.errors || []
      }
    };

    taskManager.completeTask(taskId, finalResult);

  } catch (error) {
    console.error(`‚ùå Erreur traitement asynchrone [${taskId}]:`, error);
    taskManager.failTask(taskId, error);
  }
}

// R√©cup√©rer le contenu d'un fichier CSV
exports.getFileContent = async (req, res) => {
  try {
    const { filename } = req.params;
    const fs = require('fs').promises;
    const path = require('path');
    
    console.log(`üìÑ Demande visualisation fichier: ${filename}`);
    
    // Fonction de traduction des en-t√™tes allemands vers fran√ßais avec descriptions
    const translateHeader = (germanHeader) => {
      const translations = {
        // En-t√™tes de base
        'Datum': 'Date',
        'Zeit': 'Heure',
        
        // Temp√©ratures ext√©rieures (versions ¬∞C et ÔøΩC)
        'AT [¬∞C]': 'Temp√©rature Ext√©rieure [¬∞C]',
        'AT [ÔøΩC]': 'Temp√©rature Ext√©rieure [¬∞C]',
        'ATakt [¬∞C]': 'Temp. Ext. Active [¬∞C]',
        'ATakt [ÔøΩC]': 'Temp. Ext. Active [¬∞C]',
        
        // Circuit chauffage (HK1) - versions ¬∞C et ÔøΩC
        'HK1 VL Ist[¬∞C]': 'D√©part R√©el [¬∞C]',
        'HK1 VL Ist[ÔøΩC]': 'D√©part R√©el [¬∞C]',
        'HK1 VL Soll[¬∞C]': 'D√©part Consigne [¬∞C]',
        'HK1 VL Soll[ÔøΩC]': 'D√©part Consigne [¬∞C]',
        'HK1 RT Ist[¬∞C]': 'Ambiance R√©elle [¬∞C]',
        'HK1 RT Ist[ÔøΩC]': 'Ambiance R√©elle [¬∞C]',
        'HK1 RT Soll[¬∞C]': 'Ambiance Consigne [¬∞C]',
        'HK1 RT Soll[ÔøΩC]': 'Ambiance Consigne [¬∞C]',
        'HK1 Pumpe': 'Pompe Chauff.',
        'HK1 Mischer': 'M√©langeur',
        'HK1 Fernb[¬∞C]': 'Chauff. T√©l√©commande [¬∞C]',
        'HK1 Status': 'Statut Chauffage',
        
        // Eau chaude sanitaire (WW1) - versions ¬∞C et ÔøΩC
        'WW1 EinT Ist[¬∞C]': 'ECS Entr√©e [¬∞C]',
        'WW1 EinT Ist[ÔøΩC]': 'ECS Entr√©e [¬∞C]',
        'WW1 AusT Ist[¬∞C]': 'ECS Sortie [¬∞C]',
        'WW1 AusT Ist[ÔøΩC]': 'ECS Sortie [¬∞C]',
        'WW1 Soll[¬∞C]': 'ECS Consigne [¬∞C]',
        'WW1 Soll[ÔøΩC]': 'ECS Consigne [¬∞C]',
        'WW1 Pumpe': 'Pompe ECS',
        'WW1 Status': 'Statut ECS',
        
        // Capteur externe
        'Sensor ext [¬∞C]': 'Capteur Ext. [¬∞C]',
        
        // Chaudi√®re pellets (PE1) - versions ¬∞C et ÔøΩC
        'PE1 KT[¬∞C]': 'Temp. Chaudi√®re [¬∞C]',
        'PE1 KT[ÔøΩC]': 'Temp. Chaudi√®re [¬∞C]',
        'PE1 KT_SOLL[¬∞C]': 'Chaudi√®re Consigne [¬∞C]',
        'PE1 KT_SOLL[ÔøΩC]': 'Chaudi√®re Consigne [¬∞C]',
        'PE1 UW Freigabe[¬∞C]': 'Chaudi√®re D√©gagement [¬∞C]',
        'PE1 Modulation[%]': 'Modulation [%]',
        'PE1 FRT Ist[¬∞C]': 'Temp. Fum√©es R√©elle [¬∞C]',
        'PE1 FRT Ist[ÔøΩC]': 'Temp. Fum√©es R√©elle [¬∞C]',
        'PE1 FRT Soll[¬∞C]': 'Temp. Fum√©es Consigne [¬∞C]',
        'PE1 FRT Soll[ÔøΩC]': 'Temp. Fum√©es Consigne [¬∞C]',
        'PE1 FRT End[¬∞C]': 'Foyer Temp. Finale [¬∞C]',
        'PE1 Einschublaufzeit[zs]': 'Temps Alimentation [zs]',
        'PE1 Pausenzeit[zs]': 'Temps Pause [zs]',
        'PE1 Luefterdrehzahl[%]': 'Vitesse Ventilateur [%]',
        'PE1 Saugzugdrehzahl[%]': 'Vitesse Aspiration [%]',
        'PE1 Unterdruck Ist[EH]': 'D√©pression R√©elle [EH]',
        'PE1 Unterdruck Soll[EH]': 'D√©pression Consigne [EH]',
        'PE1 Fuellstand[kg]': 'Niveau Pellets [kg]',
        'PE1 Fuellstand ZWB[kg]': 'Niveau R√©serve [kg]',
        'PE1 Status': 'Statut Chaudi√®re',
        'PE1 Statusbit': 'Bits Statut',
        
        // Moteurs et composants
        'PE1 Motor ES': 'Moteur Alimentation',
        'PE1 Motor RA': 'Moteur Cendres',
        'PE1 Motor RES1': 'Moteur R√©serve1',
        'PE1 Motor TURBINE': 'Moteur Turbine',
        'PE1 Motor ZUEND': 'Moteur Allumage',
        'PE1 Motor UW[%]': 'Moteur Circulation [%]',
        'PE1 Motor AV': 'Moteur AV',
        'PE1 Motor RES2': 'Moteur R√©serve2',
        'PE1 Motor MA': 'Moteur MA',
        'PE1 Motor RM': 'Moteur RM',
        'PE1 Motor SM': 'Moteur SM',
        
        // Temp√©ratures r√©serves et autres
        'PE1 Res1 Temp.[¬∞C]': 'Temp. R√©serve1 [¬∞C]',
        'PE1 Res2 Temp.[¬∞C]': 'Temp. R√©serve2 [¬∞C]',
        'PE1 CAP RA': 'Capacit√© RA',
        'PE1 CAP ZB': 'Capacit√© ZB',
        'PE1 AK': 'AK',
        'PE1 Saug-Int[min]': 'Intervalle Aspiration [min]',
        'PE1 DigIn1': 'Entr√©e Num√©rique 1',
        'PE1 DigIn2': 'Entr√©e Num√©rique 2',
        'PE1 CntDig1': 'Compteur Num√©rique 1',
        'PE1 Ashfill[kg]': 'Remplissage Cendres [kg]',
        'PE1 Runtime[h]': 'Temps Fonctionnement [h]',
        
        // Erreurs
        'Fehler1': 'Erreur 1',
        'Fehler2': 'Erreur 2',
        'Fehler3': 'Erreur 3',
        
        // Champ vide ou inconnu
        'PE1_BR1': 'Br√ªleur 1'
      };
      
      // Retourner la traduction ou l'original si pas de traduction
      return translations[germanHeader.trim()] || germanHeader;
    };

    // Descriptions d√©taill√©es pour les info-bulles
    const getHeaderDescription = (germanHeader) => {
      const descriptions = {
        // Horodatage
        'Datum': 'Date d\'enregistrement des donn√©es (format DD.MM.YYYY)',
        'Zeit': 'Heure d\'enregistrement des donn√©es (format HH:MM:SS)',
        
        // Temp√©rature ext√©rieure
        'AT [¬∞C]': 'Temp√©rature ext√©rieure mesur√©e par la sonde m√©t√©o. Utilis√©e pour la r√©gulation automatique de la chaudi√®re selon la courbe de chauffe.',
        'AT [ÔøΩC]': 'Temp√©rature ext√©rieure mesur√©e par la sonde m√©t√©o. Utilis√©e pour la r√©gulation automatique de la chaudi√®re selon la courbe de chauffe.',
        
        // Circuit chauffage d√©part
        'HK1 VL Ist[¬∞C]': 'Temp√©rature r√©elle du circuit de d√©part chauffage. C\'est la temp√©rature de l\'eau qui part vers les radiateurs/plancher chauffant.',
        'HK1 VL Ist[ÔøΩC]': 'Temp√©rature r√©elle du circuit de d√©part chauffage. C\'est la temp√©rature de l\'eau qui part vers les radiateurs/plancher chauffant.',
        'HK1 VL Soll[¬∞C]': 'Temp√©rature de consigne du circuit de d√©part chauffage. Calcul√©e automatiquement selon la courbe de chauffe et la temp√©rature ext√©rieure.',
        'HK1 VL Soll[ÔøΩC]': 'Temp√©rature de consigne du circuit de d√©part chauffage. Calcul√©e automatiquement selon la courbe de chauffe et la temp√©rature ext√©rieure.',
        
        // Circuit chauffage retour/ambiance
        'HK1 RT Ist[¬∞C]': 'Temp√©rature r√©elle du circuit de retour chauffage. C\'est la temp√©rature de l\'eau qui revient des radiateurs/plancher chauffant.',
        'HK1 RT Ist[ÔøΩC]': 'Temp√©rature r√©elle du circuit de retour chauffage. C\'est la temp√©rature de l\'eau qui revient des radiateurs/plancher chauffant.',
        'HK1 RT Soll[¬∞C]': 'Temp√©rature de consigne du circuit de retour chauffage. Permet d\'optimiser le rendement et d\'√©viter la condensation.',
        'HK1 RT Soll[ÔøΩC]': 'Temp√©rature de consigne du circuit de retour chauffage. Permet d\'optimiser le rendement et d\'√©viter la condensation.',
        
        // √âtats pompe/m√©langeur
        'HK1 Pumpe': '√âtat de la pompe de circulation du chauffage (0 = arr√™t, 1 = marche). Assure la circulation d\'eau dans le circuit de chauffage.',
        'HK1 Mischer': 'Position de la vanne m√©langeuse du chauffage (0-100%). M√©lange l\'eau chaude de la chaudi√®re avec l\'eau de retour pour ajuster la temp√©rature.',
        
        // Eau chaude sanitaire
        'WW1 EinT Ist[¬∞C]': 'Temp√©rature d\'entr√©e r√©elle de l\'eau chaude sanitaire dans l\'√©changeur. Eau froide qui arrive du r√©seau.',
        'WW1 EinT Ist[ÔøΩC]': 'Temp√©rature d\'entr√©e r√©elle de l\'eau chaude sanitaire dans l\'√©changeur. Eau froide qui arrive du r√©seau.',
        'WW1 AusT Ist[¬∞C]': 'Temp√©rature de sortie r√©elle de l\'eau chaude sanitaire de l\'√©changeur. Eau chaude produite pour les robinets.',
        'WW1 AusT Ist[ÔøΩC]': 'Temp√©rature de sortie r√©elle de l\'eau chaude sanitaire de l\'√©changeur. Eau chaude produite pour les robinets.',
        'WW1 Soll[¬∞C]': 'Temp√©rature de consigne pour l\'eau chaude sanitaire. R√©glable selon vos besoins de confort (g√©n√©ralement 45-60¬∞C).',
        'WW1 Soll[ÔøΩC]': 'Temp√©rature de consigne pour l\'eau chaude sanitaire. R√©glable selon vos besoins de confort (g√©n√©ralement 45-60¬∞C).',
        'WW1 Pumpe': '√âtat de la pompe de circulation ECS (0 = arr√™t, 1 = marche). Active lors des puisages ou maintien en temp√©rature.',
        
        // Chaudi√®re essentiel
        'PE1 Modulation[%]': 'Puissance de modulation du br√ªleur (0-100%). Indique l\'intensit√© de combustion des pellets pour s\'adapter aux besoins thermiques.',
        'PE1 KT[¬∞C]': 'Temp√©rature de la chaudi√®re. Temp√©rature de l\'eau dans le corps de chauffe, doit rester dans les limites de s√©curit√© (60-85¬∞C).',
        'PE1 KT[ÔøΩC]': 'Temp√©rature de la chaudi√®re. Temp√©rature de l\'eau dans le corps de chauffe, doit rester dans les limites de s√©curit√© (60-85¬∞C).',
        
        // Temp√©rature fum√©es
        'PE1 FRT Ist[¬∞C]': 'Temp√©rature r√©elle des fum√©es dans le foyer. Indicateur cl√© du rendement : trop haute = perte d\'√©nergie, trop basse = condensation.',
        'PE1 FRT Ist[ÔøΩC]': 'Temp√©rature r√©elle des fum√©es dans le foyer. Indicateur cl√© du rendement : trop haute = perte d\'√©nergie, trop basse = condensation.',
        'PE1 FRT Soll[¬∞C]': 'Temp√©rature de consigne des fum√©es. Optimis√©e automatiquement pour un rendement maximal et une combustion propre.',
        'PE1 FRT Soll[ÔøΩC]': 'Temp√©rature de consigne des fum√©es. Optimis√©e automatiquement pour un rendement maximal et une combustion propre.',
        
        // Niveau et fonctionnement
        'PE1 Fuellstand[kg]': 'Niveau de pellets dans le r√©servoir en kilogrammes. Permet de surveiller l\'autonomie restante et planifier les livraisons.',
        'PE1 Runtime[h]': 'Nombre d\'heures de fonctionnement cumul√©es de la chaudi√®re. Utile pour la maintenance pr√©ventive et le suivi des consommations.',
        
        // Erreurs
        'Fehler1': 'Code d\'erreur primaire (0 = aucune erreur). Consulter le manuel pour la signification des codes d\'erreur sp√©cifiques.',
        'Fehler2': 'Code d\'erreur secondaire (0 = aucune erreur). Erreurs moins critiques ou informations de diagnostic compl√©mentaires.',
        'Fehler3': 'Code d\'erreur tertiaire (0 = aucune erreur). Erreurs mineures ou alertes pr√©ventives de maintenance.'
      };
      
      return descriptions[germanHeader.trim()] || 'Description non disponible pour cette colonne.';
    };
    
    // Chercher dans les diff√©rents r√©pertoires possibles
    const possiblePaths = [
      path.join(__dirname, '../auto-downloads', filename),
      path.join(__dirname, '../uploads', filename),
      path.join(__dirname, '../../', filename), // Racine du projet
      path.join(__dirname, '../../auto-downloads', filename),
      path.join(__dirname, '../../backend/auto-downloads', filename),
      path.join(__dirname, '../../client/public', filename)
    ];
    
    // Recherche du fichier CSV dans les r√©pertoires possibles
    
    let filePath = null;
    let fileExists = false;
    
    // Tester chaque chemin possible
    for (const testPath of possiblePaths) {
      try {
        await fs.access(testPath);
        filePath = testPath;
        fileExists = true;
        break;
      } catch (error) {
        // Fichier non trouv√© √† ce chemin, continuer
        continue;
      }
    }
    
    if (!fileExists) {
      console.log(`‚ùå Fichier non trouv√©: ${filename}`);
      return res.status(404).json({
        success: false,
        message: 'Fichier non trouv√©'
      });
    }
    
    // Lire le contenu du fichier
    const content = await fs.readFile(filePath, 'utf-8');
    const lines = content.split('\n');
    
    // Limiter √† 500 lignes pour √©viter de surcharger l'interface
    const maxLines = 500;
    const truncated = lines.length > maxLines;
    const displayLines = lines.slice(0, maxLines);
    
    // Obtenir des infos sur le fichier
    const stats = await fs.stat(filePath);
    
    console.log(`‚úÖ Fichier lu: ${filename}, ${lines.length} lignes, ${(stats.size / 1024).toFixed(2)} KB`);
    
    // Colonnes essentielles √† conserver (avec variantes d'encodage)
    const essentialColumns = [
      // Horodatage
      'Datum', 'Zeit',
      
      // Temp√©rature ext√©rieure (ATakt plus pr√©cis, mais on garde AT comme demand√©)
      'AT [¬∞C]', 'AT [ÔøΩC]',
      
      // Circuit chauffage d√©part
      'HK1 VL Ist[¬∞C]', 'HK1 VL Ist[ÔøΩC]',
      'HK1 VL Soll[¬∞C]', 'HK1 VL Soll[ÔøΩC]',
      
      // Circuit chauffage retour/ambiance
      'HK1 RT Ist[¬∞C]', 'HK1 RT Ist[ÔøΩC]',
      'HK1 RT Soll[¬∞C]', 'HK1 RT Soll[ÔøΩC]',
      
      // √âtats pompe/m√©langeur
      'HK1 Pumpe', 'HK1 Mischer',
      
      // Eau chaude sanitaire
      'WW1 EinT Ist[¬∞C]', 'WW1 EinT Ist[ÔøΩC]',
      'WW1 AusT Ist[¬∞C]', 'WW1 AusT Ist[ÔøΩC]',
      'WW1 Soll[¬∞C]', 'WW1 Soll[ÔøΩC]',
      'WW1 Pumpe',
      
      // Chaudi√®re essentiel
      'PE1 Modulation[%]',
      'PE1 KT[¬∞C]', 'PE1 KT[ÔøΩC]',
      
      // Temp√©rature fum√©es
      'PE1 FRT Ist[¬∞C]', 'PE1 FRT Ist[ÔøΩC]',
      'PE1 FRT Soll[¬∞C]', 'PE1 FRT Soll[ÔøΩC]',
      
      // Niveau et fonctionnement
      'PE1 Fuellstand[kg]',
      'PE1 Runtime[h]',
      
      // Erreurs
      'Fehler1', 'Fehler2', 'Fehler3'
    ];
    
    // Traiter les en-t√™tes pour les traduire et filtrer
    const originalHeaders = displayLines[0] ? displayLines[0].split(';') : [];
    const translatedHeaders = originalHeaders.map(header => translateHeader(header));
    
    // Identifier les indices des colonnes √† conserver
    const visibleColumnIndices = [];
    originalHeaders.forEach((header, index) => {
      if (essentialColumns.includes(header.trim())) {
        visibleColumnIndices.push(index);
      }
    });
    
    // Filtrer les en-t√™tes (garder seulement les essentielles)
    const visibleHeaders = translatedHeaders.filter((_, index) => visibleColumnIndices.includes(index));
    const visibleOriginalHeaders = originalHeaders.filter((_, index) => visibleColumnIndices.includes(index));
    
    // Cr√©er les descriptions pour les colonnes visibles
    const headerDescriptions = visibleOriginalHeaders.map(header => getHeaderDescription(header));
    
    // Filtrer les donn√©es (garder seulement les colonnes essentielles)
    const filteredContent = displayLines.map(line => {
      const cells = line.split(';');
      return cells.filter((_, index) => visibleColumnIndices.includes(index)).join(';');
    });
    
    console.log(`üîÑ Colonnes essentielles: ${originalHeaders.length} ‚Üí ${visibleHeaders.length} colonnes (${originalHeaders.length - visibleHeaders.length} masqu√©es)`);
    
    res.json({
      success: true,
      fileData: {
        filename: filename,
        totalLines: lines.length,
        displayLines: displayLines.length,
        truncated: truncated,
        size: stats.size,
        sizeFormatted: `${(stats.size / 1024).toFixed(2)} KB`,
        lastModified: stats.mtime,
        content: filteredContent,
        headers: visibleHeaders,
        originalHeaders: visibleOriginalHeaders, // En-t√™tes originaux visibles
        headerDescriptions: headerDescriptions, // Descriptions pour les info-bulles
        visibleColumns: visibleColumnIndices.length, // Nombre de colonnes affich√©es
        totalColumns: originalHeaders.length // Nombre total de colonnes
      }
    });
    
  } catch (error) {
    console.error('‚ùå Erreur lecture fichier:', error);
    res.status(500).json({
      success: false,
      message: 'Erreur lors de la lecture du fichier',
      error: error.message
    });
  }
};

// R√©cup√©rer les donn√©es de temp√©rature pour graphique journalier
exports.getTemperatureData = async (req, res) => {
  try {
    const { filename } = req.params;
    const fs = require('fs').promises;
    const path = require('path');
    
    console.log(`üìä Demande donn√©es temp√©rature pour: ${filename}`);
    console.log(`üîç R√©pertoire de travail: ${process.cwd()}`);
    
    // Construire le chemin complet du fichier 
    // Le serveur s'ex√©cute depuis la racine, donc pas besoin d'ajouter 'backend'
    const autoDownloadsPath = path.join(process.cwd(), 'auto-downloads');
    const filePath = path.join(autoDownloadsPath, filename);
    
    console.log(`üìÅ Chemin calcul√©: ${filePath}`);
    
    // V√©rifier que le fichier existe
    try {
      await fs.access(filePath);
    } catch (error) {
      return res.status(404).json({
        success: false,
        message: 'Fichier non trouv√©'
      });
    }
    
    // Lire le fichier CSV
    const fileContent = await fs.readFile(filePath, 'utf-8');
    const lines = fileContent.split('\n').filter(line => line.trim());
    
    if (lines.length < 2) {
      return res.status(400).json({
        success: false,
        message: 'Fichier CSV invalide ou vide'
      });
    }
    
    // Parser les donn√©es
    const headers = lines[0].split(';');
    const temperatureData = [];
    
    // Trouver les indices des colonnes qui nous int√©ressent
    let dateIndex = -1, timeIndex = -1, ambientTempIndex = -1, targetTempIndex = -1, outdoorTempIndex = -1;
    
    headers.forEach((header, index) => {
      const cleanHeader = header.trim();
      if (cleanHeader === 'Datum') dateIndex = index;
      else if (cleanHeader === 'Zeit') timeIndex = index;
      else if (cleanHeader.includes('HK1 RT Ist[') && cleanHeader.includes('C]')) ambientTempIndex = index; // Temp√©rature r√©elle
      else if (cleanHeader.includes('HK1 RT Soll[') && cleanHeader.includes('C]')) targetTempIndex = index; // Temp√©rature de consigne
      else if (cleanHeader.includes('ATakt [') && cleanHeader.includes('C]')) outdoorTempIndex = index; // Temp√©rature ext√©rieure
    });
    
    if (dateIndex === -1 || timeIndex === -1 || ambientTempIndex === -1 || targetTempIndex === -1 || outdoorTempIndex === -1) {
      return res.status(400).json({
        success: false,
        message: 'Colonnes de temp√©rature non trouv√©es dans le fichier',
        found: {
          date: dateIndex !== -1,
          time: timeIndex !== -1,
          ambientTemp: ambientTempIndex !== -1,
          targetTemp: targetTempIndex !== -1,
          outdoorTemp: outdoorTempIndex !== -1
        }
      });
    }
    
    // Parser chaque ligne de donn√©es
    for (let i = 1; i < lines.length; i++) {
      const values = lines[i].split(';');
      
      if (values.length > Math.max(dateIndex, timeIndex, ambientTempIndex, targetTempIndex, outdoorTempIndex)) {
        const date = values[dateIndex]?.trim();
        const time = values[timeIndex]?.trim();
        const realTemp = parseFloat(values[ambientTempIndex]?.trim().replace(',', '.'));
        const setpointTemp = parseFloat(values[targetTempIndex]?.trim().replace(',', '.'));
        const outdoorTemp = parseFloat(values[outdoorTempIndex]?.trim().replace(',', '.'));
        
        // Cr√©er un timestamp combin√©
        if (date && time && !isNaN(realTemp) && !isNaN(setpointTemp) && !isNaN(outdoorTemp)) {
          // Convertir la date allemande (DD.MM.YYYY) en format ISO
          const [day, month, year] = date.split('.');
          const timestamp = new Date(`${year}-${month}-${day}T${time}`);
          
          temperatureData.push({
            timestamp: timestamp.toISOString(),
            realTemp,
            setpointTemp,
            outdoorTemp
          });
        }
      }
    }
    
    // Trier par timestamp
    temperatureData.sort((a, b) => new Date(a.timestamp) - new Date(b.timestamp));
    
    res.json({
      success: true,
      data: {
        filename,
        totalPoints: temperatureData.length,
        temperatureData
      }
    });
    
  } catch (error) {
    console.error('‚ùå Erreur r√©cup√©ration donn√©es temp√©rature:', error);
    res.status(500).json({
      success: false,
      message: 'Erreur lors de la r√©cup√©ration des donn√©es de temp√©rature',
      error: error.message
    });
  }
};